{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative sensitivity analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized Sobol Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here we show how to compute generalized Sobol indices on the **EOQ** model using the algorithm presented in Kucherenko et al. 2012. We import our model function from ``temfpy`` and use the Kucherenko indices function from ``econsa``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # noqa: F401\n",
    "import numpy as np\n",
    "\n",
    "from temfpy.uncertainty_quantification import eoq_model\n",
    "\n",
    "# TODO: Reactivate once Tim's PR is ready.\n",
    "# from econsa.kucherenko import kucherenko_indices  # noqa: E265"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function ``kucherenko_indices`` expects the input function to be broadcastable over rows, that is, a row represents the input arguments for one evaluation. For sampling around the mean parameters we specify a diagonal covariance matrix, where the variances depend on the scaling of the mean. Since the variances of the parameters are unknown prior to our analysis we choose values such that the probability of sampling negative values is negligible. We do this since the **EOQ** model is not defined for negative parameters and the normal sampling does not naturally account for bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eoq_model_transposed(x):\n",
    "    \"\"\"EOQ Model but with variables stored in columns.\"\"\"\n",
    "    return eoq_model(x.T)\n",
    "\n",
    "\n",
    "mean = np.array([1230, 0.0135, 2.15])\n",
    "cov = np.diag([1, 0.000001, 0.01])\n",
    "\n",
    "# indices = kucherenko_indices( # noqa: E265\n",
    "#    func=eoq_model_transposed, # noqa: E265\n",
    "#    sampling_mean=mean,  # noqa: E265\n",
    "#    sampling_cov=cov,  # noqa: E265\n",
    "#    n_draws=1_000_000,  # noqa: E265\n",
    "#    sampling_scheme=\"sobol\",  # noqa: E265\n",
    "# )  # noqa: E265"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to inspect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# sobol_first = indices.loc[(slice(None), \"first_order\"), \"value\"].values  # noqa: E265\n",
    "# sobol_total = indices.loc[(slice(None), \"total\"), \"value\"].values # noqa: E265\n",
    "\n",
    "# x = np.arange(3)  # the label locations  # noqa: E265\n",
    "# width = 0.35  # the width of the bars  # noqa: E265\n",
    "\n",
    "# fig, ax = plt.subplots()  # noqa: E265\n",
    "# rects1 = ax.bar(x - width / 2, sobol_first, width, label=\"First-order\")  # noqa: E265\n",
    "# rects2 = ax.bar(x + width / 2, sobol_total, width, label=\"Total\")  # noqa: E265\n",
    "\n",
    "# ax.set_ylim([0, 1])  # noqa: E265\n",
    "# ax.legend()  # noqa: E265\n",
    "\n",
    "# ax.set_xticks(x)  # noqa: E265\n",
    "# ax.set_xticklabels([\"$x_0$\", \"$x_1$\", \"$x_2$\"])  # noqa: E265\n",
    "# ax.legend();  # noqa: E265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig  # noqa: E265"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tutorial, we give a brief notational overview of variance-based sensitivity analysis as well as the Shapley value's theoratical framework (:cite:`Song.2016`). Furthermore, we illustrate how to estimate Shapley effects in the context of a model with dependent inputs.\n",
    "\n",
    "In this illustrative overview, we follow the framework on variance-based sensitivity analysis and Shapley values developed by :cite:`Song.2016`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Based Sensitivity Analysis: A Snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a model with $k$ inputs denoted by $X_K = \\{X_1, X_2, X_3, \\dots, X_k \\}$ where $K = \\{1, 2, \\dots, k\\}$. Consider also $X_J$, which indicates the vector of inputs included in the index set $J \\subseteq X$. The uncertainty in $X_K$ is represented by the joint cumulative distribution $G_K$. Furthermore, we denote the joint distribution of inputs included in the index set $J$ as $G_J$ and the marginal distribution of each $X_i$ as $G_i$. The model is treated as a blackbox, and only the model response is analysed. The model response $Y$ is a function of the inputs, i.e., $Y = f(X_K)$ and therefore $f(X_K)$ is stochastic due to the uncertainty in $X_K$ although $f(\\cdot)$ is deterministic. Often, $f(\\cdot)$ has a complex structure, and does not have a closed form expression. The overall uncertainty in the model output $Y$ caused by $X_K$ is $Var[Y]$, where the variance is calculated with respect to the joint distribution $G_K$. The Shapley value then, helps us to quantify how much of $Var[Y]$ can be attributed to each each $X_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapley Values: A Theoratical Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An analogous framework to the one developed for variance-based sensitivity analysis above is apparent in the specification of the Shapley value. Formally, a \\textit{k-player game} with the set of players $K = \\{1,2, \\dots, k\\}$ is defined as a real valued function that maps a subset of $K$ to its corresponding cost (or value), i.e., $c: 2^K \\rightarrow  {\\rm I\\!R}$ with $c(\\emptyset) = 0$. With this in mind, $c(J)$ then, represents the cost that arises when the players in the subset $J$ of $K$ participate in the game. The Shapley value for player $i$ with respect to $c(\\cdot)$ is defined as \n",
    "\n",
    "\\begin{equation}\n",
    "\\label{eqn:shapley}\n",
    "v_i = \\sum_{J \\subseteq K \\backslash \\{i\\}}^{} \\frac{(k -|J| - 1)! |J|!}{k!} \\cdot (c(J \\cup \\{i\\}) -c(J)),\n",
    "\\end{equation}\n",
    "where $|J|$ indicates the size of $J$. In other words, $v_i$ is the incremental cost of including player $i$ in set $J$ averaged over all sets $J \\subseteq K \\backslash \\{i\\}$.  The Shapley value gives equal weight to each $k$ subset sizes and equal weights amongst the subsets of the same size, which is important in determining the fairness of the variance allocation in the calculation of Shapley effects in variance-based sensitivity analysis (:cite:`Song.2016`).  Reconciling the two frameworks by direct comparison, we can think of the set of $K$ players as the set of inputs of $f(\\cdot)$ and define $c(\\cdot)$ so that for $J \\subseteq K$, $c(J)$ measures the variance of $Y$ caused by the uncertainty of the inputs in $J$. \n",
    "\n",
    "The ideal $c(\\cdot)$ should satisfy the conditions: $c(\\emptyset) = 0$ and $c(K) = Var[Y]$. Two such candidates for such $c(\\cdot)$ can be considered, and have been shown to be equivalent are equivalent (:cite:`Song.2016`).\n",
    "The first cost function is \n",
    "\\begin{equation}\n",
    "\\label{eqn:costone}\n",
    "\\tilde{c}(J) = Var[E[Y|X_J]].\n",
    "\\end{equation}\n",
    "This cost function satisfies the two conditions from above and was originally put forth by :cite:`Owen.2014` and later adopted by :cite:`Song.2016` in their paper. The cost function can be rewritten as $\\tilde{c}(J) = Var[Y] - E[Var[Y|X_J]]$, and interpreted as the expected reduction in the output variance when the values of $X_J$ are known. The second cost function that satisfies the required conditions is\n",
    "\\begin{equation}\n",
    "\\label{eqn:costtwo}\n",
    "c(J) = E[Var[Y|X_{-J}]]\n",
    "\\end{equation}\n",
    "where $X_{-J} = X_{K \\backslash J} $. $c(J)$ is interpreted as the expected remaining variance in $Y$ when the values of $X_{-J} $ are known. In this case, the incremental cost $c(J \\cup \\{i\\}) -c(J)$ can be interpreted as the expected decrease in the variance of $Y$ conditional on the known input values of $X_i$ out of all the unknown inputs in $J \\cup \\{i\\}$. \n",
    "\n",
    "Although both cost functions result in the same Shapley values, their resultant estimators from Monte Carlo simulation are different. :cite:`Sun.2011` reveal that the Monte Carlo estimator that results from the simulation of $\\tilde{c}(J)$ can be severely biased if the inner level sample size used to estimate the conditional expectation is not large enough. Given the already computationally demanding structure of microeconomic models, this added computational complexity is costly. In contrast however, the estimator of $c(J)$ is unbiased for all sample sizes. Because of this added feature, we follow :cite:`Song.2016` in using the cost function $c(J)$ rather that $\\tilde{c}(J)$. We therefore define the \\textit{Shapley effect} of the $i_{th}$ input, $Sh_i$, as the Shapley value obtained by applying the cost function $c(J)$ to \\autoref{eqn:shapley}. Indeed, any Shapley value defined by the satisfaction of the two conditions: $c(\\emptyset) = 0$ and $c(K) = Var[Y]$ imply that\n",
    "\\begin{equation}\n",
    "\\label{eqn:variance_sum}\n",
    "\\sum_{k}^{i=1} Sh_i = Var[Y],\n",
    "\\end{equation}\n",
    "even if there is dependence or structural interactions amongst the elements in $X_K$. \n",
    "\n",
    "From here on out, we use $Sh_i$ to denote the Shapley effect and $v_i$ to denote the generic Shapley value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial: A Linear Model with Three Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an understanding of just how the Shapley effects can be applied to economic models, we illustrate the method in a simple to follow and understand linear model with three inputs. \n",
    "\n",
    "#### The model\n",
    "Consider the linear model:\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{eq: gaussianlinear}\n",
    "Y = \\beta_{0} + \\beta^T \\textbf{X}.\n",
    "\\end{equation}\n",
    "\n",
    "with constants $\\beta_{0} \\in {\\rm I\\!R}$, $\\beta \\in {\\rm I\\!R^3}$ and $ X \\sim \\mathcal{N}(0,\\,\\sum)\\,$ with the covariance matrix:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\sum = \n",
    "\\begin{pmatrix}\n",
    "\\sigma_1^2 & \\sigma_{12} & \\sigma_{13} \\\\\n",
    " \\sigma_{21} & \\sigma_2^2 & \\sigma_{23}\\\\\n",
    " \\sigma_{31} & \\sigma_{32} & \\sigma_3^2 \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "where $ \\sigma_1 > 0, \\sigma_2 > 0, \\sigma_3 > 0.$\n",
    "\n",
    "In this simplistic illustration, we have that $\\sigma_1 = \\sigma_2 = 1$, $\\sigma_3 = 4$ and then correlate $X_2$ and $X_3$. The resulting covariance matrix is\n",
    "\n",
    "\\begin{equation*}\n",
    "\\sum = \n",
    "\\begin{pmatrix}\n",
    "1.0 & 0 & 0 \\\\\n",
    "0 & 1.0 & 1.8\\\\\n",
    "0 & 1.8 & 4 \\\\\n",
    "\\end{pmatrix}\n",
    ".\n",
    "\\end{equation*}\n",
    "\n",
    "All eigenvalues of $\\sigma$ are positive which verifies that the constructed covariance matrix is positive definite. With this setup, we conduct SA using the Shapley effects method. To use the `get_shapley` function, you will need both the vector of paramters and the covariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages and functions\n",
    "import numpy as np\n",
    "import chaospy as cp\n",
    "\n",
    "from econsa.shapley import get_shapley\n",
    "from econsa.shapley import _r_condmvn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all neccesary inputs for the model, you will need:\n",
    "- a vector of mean estimates\n",
    "- a covariance matrix\n",
    "- the model you are conducting SA on\n",
    "- the functions ``x_all`` and ``x_cond`` for conditional sampling. These functions depend on the distribution from which you are sampling from - for the purposes of this ilustration, we will sample from a multvariate normal distribution, but the functions can be tailored to needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and covaraince matrix inputs\n",
    "np.random.seed(123)\n",
    "n_inputs = 3\n",
    "mean = np.zeros(3)\n",
    "cov = np.array([[1.0, 0, 0], [0, 1.0, 1.8], [0, 1.8, 4.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for which SA is being performed\n",
    "def gaussian_model(X):\n",
    "    return np.sum(X,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for conditional sampling\n",
    "def x_all(n):\n",
    "    distribution = cp.MvNormal(mean, cov)\n",
    "    return distribution.sample(n)\n",
    "\n",
    "def x_cond(n, subset_j, subsetj_conditional, xjc):\n",
    "    if subsetj_conditional is None:\n",
    "        cov_int = np.array(cov)\n",
    "        cov_int = cov_int.take(subset_j, axis = 1)\n",
    "        cov_int = cov_int[subset_j]\n",
    "        distribution = cp.MvNormal(mean[subset_j], cov_int)\n",
    "        return distribution.sample(n)\n",
    "    else:\n",
    "        return _r_condmvn(n, mean = mean, cov = cov, dependent_ind = subset_j, given_ind = subsetj_conditional, x_given = xjc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shapley effects</th>\n",
       "      <th>std. errors</th>\n",
       "      <th>CI_min</th>\n",
       "      <th>CI_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X1</th>\n",
       "      <td>0.101309</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.096575</td>\n",
       "      <td>0.106044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2</th>\n",
       "      <td>0.418989</td>\n",
       "      <td>0.162970</td>\n",
       "      <td>0.099568</td>\n",
       "      <td>0.738410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X3</th>\n",
       "      <td>0.479701</td>\n",
       "      <td>0.163071</td>\n",
       "      <td>0.160083</td>\n",
       "      <td>0.799320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Shapley effects  std. errors    CI_min    CI_max\n",
       "X1         0.101309     0.002415  0.096575  0.106044\n",
       "X2         0.418989     0.162970  0.099568  0.738410\n",
       "X3         0.479701     0.163071  0.160083  0.799320"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimate Shapley effects using the exact method\n",
    "method = 'exact'\n",
    "n_perms = None\n",
    "n_output = 10**4\n",
    "n_outer = 10**3\n",
    "n_inner = 10**2\n",
    "\n",
    "get_shapley(method, gaussian_model, x_all, x_cond, n_perms, n_inputs, n_output, n_outer, n_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shapley effects</th>\n",
       "      <th>std. errors</th>\n",
       "      <th>CI_min</th>\n",
       "      <th>CI_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X1</th>\n",
       "      <td>0.111083</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.116903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2</th>\n",
       "      <td>0.415180</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.409023</td>\n",
       "      <td>0.421337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X3</th>\n",
       "      <td>0.473737</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.467543</td>\n",
       "      <td>0.479931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Shapley effects  std. errors    CI_min    CI_max\n",
       "X1         0.111083     0.002969  0.105263  0.116903\n",
       "X2         0.415180     0.003141  0.409023  0.421337\n",
       "X3         0.473737     0.003160  0.467543  0.479931"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimate Shapley effects using the random method\n",
    "method = 'random'\n",
    "n_perms = 30000\n",
    "n_output = 10**4\n",
    "n_outer = 1\n",
    "n_inner = 3\n",
    "\n",
    "\n",
    "get_shapley(method, gaussian_model, x_all, x_cond, n_perms, n_inputs, n_output, n_outer, n_inner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there we have the resultant Shapley effects, in line witht he chosen method of estimation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
